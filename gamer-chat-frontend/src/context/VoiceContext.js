import React, { createContext, useContext, useEffect, useRef, useState } from 'react';
import { SocketContext } from './SocketContext';
import { AuthContext } from './AuthContext';
import { API_URL } from '../config';

export const VoiceContext = createContext();

export const VoiceProvider = ({ children }) => {
  const { socket, connected } = useContext(SocketContext);
  const { user } = useContext(AuthContext);
  
  const [localStream, setLocalStream] = useState(null);
  const [localScreenStream, setLocalScreenStream] = useState(null);
  const [remoteStreams, setRemoteStreams] = useState({}); // { userId: audioStream }
  const [remoteCameraStreams, setRemoteCameraStreams] = useState({}); // { userId: cameraStream }
  const [remoteScreenStreams, setRemoteScreenStreams] = useState({}); // { userId: screenStream }
  const [isInVoice, setIsInVoice] = useState(false);
  const [voiceParticipants, setVoiceParticipants] = useState([]); // Array of userIds or {userId, username}
  const [isMuted, setIsMuted] = useState(false);
  const [isDeafened, setIsDeafened] = useState(false);
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [isSharingScreen, setIsSharingScreen] = useState(false);
  const [currentGroupId, setCurrentGroupId] = useState(null);
  const [isWhispering, setIsWhispering] = useState(false);
  const [whisperTarget, setWhisperTarget] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [highlights, setHighlights] = useState([]);
  const [privateCall, setPrivateCall] = useState({ status: 'idle', targetUser: null, isVideo: false, incomingOffer: null });
  const [voicePreview, setVoicePreview] = useState({}); // { groupId: [users] } - shows who's in voice WITHOUT joining

  const peerConnections = useRef({}); // { userId: RTCPeerConnection }
  const candidateQueues = useRef({}); // { userId: [RTCIceCandidate] }
  const mediaRecorder = useRef(null);
  const analyserRef = useRef(null);
  const audioContextRef = useRef(null);
  const animationFrameRef = useRef(null);
  const audioChunks = useRef([]);

  // Sound effect helper - simple beep tones
  const playJoinSound = () => {
    try {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();
      osc.connect(gain);
      gain.connect(ctx.destination);
      osc.frequency.value = 880; // A5 note
      osc.type = 'sine';
      gain.gain.setValueAtTime(0.3, ctx.currentTime);
      gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.2);
      osc.start(ctx.currentTime);
      osc.stop(ctx.currentTime + 0.2);
    } catch (e) {
      console.log('Could not play join sound');
    }
  };

  const playLeaveSound = () => {
    try {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();
      osc.connect(gain);
      gain.connect(ctx.destination);
      osc.frequency.value = 440; // A4 note (lower pitch for leave)
      osc.type = 'sine';
      gain.gain.setValueAtTime(0.3, ctx.currentTime);
      gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.3);
      osc.start(ctx.currentTime);
      osc.stop(ctx.currentTime + 0.3);
    } catch (e) {
      console.log('Could not play leave sound');
    }
  };
  
  // Refs to avoid stale closures in socket handlers
  const localStreamRef = useRef(null);
  const isInVoiceRef = useRef(false);
  const currentGroupIdRef = useRef(null);
  const privateCallRef = useRef({ status: 'idle', targetUser: null, isVideo: false, incomingOffer: null });

  // Sync privateCallRef whenever privateCall state changes
  useEffect(() => {
    privateCallRef.current = privateCall;
  }, [privateCall]);

  // 1. Get User Media
  const startLocalStream = async (video = false) => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: true, 
        video: video 
      });
      setLocalStream(stream);
      localStreamRef.current = stream;

      // --- Setup Audio Analyser for Emotion Detection ---
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      }
      const source = audioContextRef.current.createMediaStreamSource(stream);
      const analyser = audioContextRef.current.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyserRef.current = analyser;

      return stream;
    } catch (error) {
      console.error('Error accessing microphone/camera:', error);
      return null;
    }
  };

  // 2. Join Voice Channel
  const joinVoice = async (groupId) => {
    if (!connected) return;
    
    // Guard: If already in THIS voice channel, do nothing
    if (isInVoice && currentGroupId === groupId) return;
    
    // Guard: If in a DIFFERENT voice channel, leave it first
    if (isInVoice) {
      leaveVoice();
    }

    const stream = await startLocalStream();
    if (!stream) return;

    // Sync refs for socket handlers
    localStreamRef.current = stream;
    isInVoiceRef.current = true;
    currentGroupIdRef.current = groupId;

    setCurrentGroupId(groupId);
    setIsInVoice(true);
    setVoiceParticipants([{ _id: user.id || user._id, username: user.username }]);
    localStorage.setItem('lastVoiceGroupId', groupId);
    socket.emit('join-voice', { groupId });
    
    // Play join sound
    playJoinSound();
  };

  const leaveVoice = () => {
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      setLocalStream(null);
      localStreamRef.current = null;
    }
    
    // Close all peer connections
    Object.values(peerConnections.current).forEach(pc => pc.close());
    peerConnections.current = {};
    setRemoteStreams({});
    setRemoteCameraStreams({});
    setRemoteScreenStreams({});
    
    if (currentGroupId) {
      socket.emit('leave-voice', { groupId: currentGroupId });
    }
    
    if (isSharingScreen) {
      stopScreenShare();
    }

    setIsInVoice(false);
    isInVoiceRef.current = false;
    setVoiceParticipants([]);
    setCurrentGroupId(null);
    currentGroupIdRef.current = null;
    localStorage.removeItem('lastVoiceGroupId');
    
    // Play leave sound
    playLeaveSound();
  };

  // Screen Sharing
  const startScreenShare = async () => {
    try {
      const stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
      setLocalScreenStream(stream);
      setIsSharingScreen(true);

      // Re-negotiate with all peers to add screen track
      Object.entries(peerConnections.current).forEach(async ([userId, pc]) => {
        stream.getTracks().forEach(track => pc.addTrack(track, stream));
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        socket.emit('webrtc-offer', { targetId: userId, offer, groupId: currentGroupId });
      });

      stream.getVideoTracks()[0].onended = () => {
        stopScreenShare();
      };
    } catch (error) {
      console.error('Error starting screen share:', error);
    }
  };

  const stopScreenShare = () => {
    if (localScreenStream) {
      localScreenStream.getTracks().forEach(track => {
        track.stop();
        // Remove track from all peer connections
        Object.values(peerConnections.current).forEach(pc => {
          const sender = pc.getSenders().find(s => s.track === track);
          if (sender) pc.removeTrack(sender);
        });
      });
      setLocalScreenStream(null);
    }
    setIsSharingScreen(false);
    
    // Renegotiate to signal track removal
    Object.entries(peerConnections.current).forEach(async ([userId, pc]) => {
      try {
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        socket.emit('webrtc-offer', { targetId: userId, offer, groupId: currentGroupId });
      } catch (e) {
        console.error("Renegotiation error after screen share stop", e);
      }
    });
  };

  // Camera Toggling
  const toggleCamera = async () => {
    try {
      if (!localStream) {
        console.error('No local stream available for camera toggle');
        return;
      }
      
      if (isCameraOn) {
        // Stop camera tracks
        const videoTracks = localStream.getVideoTracks();
        videoTracks.forEach(track => {
          track.stop();
          // Remove from peer connections
          Object.values(peerConnections.current).forEach(pc => {
            const sender = pc.getSenders().find(s => s.track === track);
            if (sender) {
              pc.removeTrack(sender);
            }
          });
          // Remove from localStream
          localStream.removeTrack(track);
        });
        setIsCameraOn(false);
      } else {
        // Start camera tracks
        const cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
        const videoTrack = cameraStream.getVideoTracks()[0];
        
        // Add to localStream
        localStream.addTrack(videoTrack);
        
        // Add to all peer connections
        Object.values(peerConnections.current).forEach(pc => {
          pc.addTrack(videoTrack, localStream);
        });
        
        setIsCameraOn(true);
      }
      
      // Renegotiate with all peers
      Object.entries(peerConnections.current).forEach(async ([userId, pc]) => {
        try {
          const offer = await pc.createOffer();
          await pc.setLocalDescription(offer);
          socket.emit('webrtc-offer', { targetId: userId, offer, groupId: currentGroupId });
        } catch (e) {
          console.error('Renegotiation error after camera toggle:', e);
        }
      });
    } catch (error) {
      console.error('Error toggling camera:', error);
      alert('Could not access camera. Please check permissions.');
    }
  };

  // 4. Create Peer Connection
  const createPeerConnection = (targetUserId, stream, isPrivate = false) => {
    const pc = new RTCPeerConnection({
      iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
    });

    pc.onicecandidate = (event) => {
      if (event.candidate) {
        if (isPrivate) {
          socket.emit('private-call-ice-candidate', {
            targetUserId: targetUserId,
            candidate: event.candidate
          });
        } else {
          socket.emit('webrtc-ice-candidate', {
            targetId: targetUserId,
            candidate: event.candidate
          });
        }
      }
    };

    pc.ontrack = (event) => {
      const track = event.track;
      // Use the first stream provided, or create one if none exists (robustness)
      const stream = event.streams && event.streams.length > 0 ? event.streams[0] : new MediaStream([track]);
      
      console.log(`[WebRTC] Received ${track.kind} track from ${targetUserId}`);

      if (track.kind === 'audio') {
        setRemoteStreams(prev => ({ ...prev, [targetUserId]: stream }));
      } else if (track.kind === 'video') {
        // Distinguish between camera and screen share
        const isScreen = stream.id.includes('screen') || 
                         track.label.toLowerCase().includes('screen') || 
                         track.label.toLowerCase().includes('window');
        
        if (isScreen) {
          setRemoteScreenStreams(prev => ({ ...prev, [targetUserId]: stream }));
        } else {
          setRemoteCameraStreams(prev => ({ ...prev, [targetUserId]: stream }));
        }
      }
    };

    if (stream) {
      stream.getTracks().forEach(track => {
        pc.addTrack(track, stream);
      });
    }

    return pc;
  };

  // Helper to add ICE candidate with queuing logic
  const addCandidate = async (targetUserId, candidate) => {
    const pc = peerConnections.current[targetUserId];
    if (pc && pc.remoteDescription && pc.remoteDescription.type) {
      try {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
      } catch (e) {
        console.error("Error adding received ice candidate", e);
      }
    } else {
      if (!candidateQueues.current[targetUserId]) {
        candidateQueues.current[targetUserId] = [];
      }
      candidateQueues.current[targetUserId].push(candidate);
    }
  };

  // Helper to process queued candidates after remote description is set
  const processQueuedCandidates = (targetUserId) => {
    const queue = candidateQueues.current[targetUserId];
    if (queue && queue.length > 0) {
      queue.forEach(candidate => addCandidate(targetUserId, candidate));
      candidateQueues.current[targetUserId] = [];
    }
  };

  // --- AI EMOTION DETECTION LOOP ---
  useEffect(() => {
    if (!isInVoice || !analyserRef.current || isRecording) return;

    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    const checkEnergy = () => {
      if (!analyserRef.current) return;
      
      analyserRef.current.getByteFrequencyData(dataArray);
      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        sum += dataArray[i];
      }
      const average = sum / bufferLength;
      
      // Threshold for "Hype" (roughly shouting/cheering)
      if (average > 120 && !isRecording) {
        console.log("üî• High Energy Detected! Starting Auto-Highlight...");
        startRecording();
        
        // Record for 8 seconds
        setTimeout(() => {
          stopRecording();
        }, 8000);
      }
      
      animationFrameRef.current = requestAnimationFrame(checkEnergy);
    };

    animationFrameRef.current = requestAnimationFrame(checkEnergy);

    return () => {
      if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    };
  }, [isInVoice, isRecording]);

  const startRecording = () => {
    if (!localStream) return;
    
    audioChunks.current = [];
    mediaRecorder.current = new MediaRecorder(localStream);
    
    mediaRecorder.current.ondataavailable = (event) => {
      audioChunks.current.push(event.data);
    };

    mediaRecorder.current.onstop = uploadAudioSession;

    mediaRecorder.current.start();
    setIsRecording(true);
  };

  const stopRecording = () => {
    if (mediaRecorder.current && isRecording) {
      mediaRecorder.current.stop();
      setIsRecording(false);
    }
  };

  const uploadAudioSession = async () => {
    const audioBlob = new Blob(audioChunks.current, { type: 'audio/webm' });
    const formData = new FormData();
    formData.append('audio', audioBlob, 'session.webm');
    formData.append('groupId', currentGroupId);

    try {
      const response = await fetch(`${API_URL}/api/ai/upload-session`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${user.token}`
        },
        body: formData
      });

      const data = await response.json();
      if (data.highlights) {
        setHighlights(data.highlights);
        alert(`Found ${data.highlights.length} highlights! Check the sidebar.`);
      }
    } catch (error) {
      console.error('Error uploading audio session:', error);
    }
  };

  // Auto-join on mount if saved in localStorage
  useEffect(() => {
    if (connected && user) {
      const savedGroupId = localStorage.getItem('lastVoiceGroupId');
      if (savedGroupId && !isInVoice) {
        console.log("Auto-rejoining voice channel:", savedGroupId);
        joinVoice(savedGroupId);
      }
    }
  }, [connected, !!user]);

  // Handle Socket Events
  useEffect(() => {
    if (!socket) return;

    // A new user joined voice - we (as an existing user) send an offer
    socket.on('user-joined-voice', async (data) => {
      const { userId, username } = data;
      // Use refs to avoid stale closure issue
      if (!isInVoiceRef.current || !localStreamRef.current) return;
      
      console.log(`User ${username} joined voice. Sending offer...`);
      
      setVoiceParticipants(prev => {
        if (!prev.find(p => p._id === userId)) {
          return [...prev, { _id: userId, username }];
        }
        return prev;
      });

      const pc = createPeerConnection(userId, localStreamRef.current);
      peerConnections.current[userId] = pc;
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      socket.emit('webrtc-offer', { targetId: userId, offer, groupId: currentGroupIdRef.current });
    });

    socket.on('voice-channel-users', (data) => {
      // Received list of users already in voice when joining
      setVoiceParticipants(data.users);
    });

    socket.on('webrtc-offer', async (data) => {
      const { offer, senderId, senderUsername } = data;
      // Use refs to avoid stale closure issue
      if (!isInVoiceRef.current || !localStreamRef.current) return;
      
      const pc = createPeerConnection(senderId, localStreamRef.current);
      peerConnections.current[senderId] = pc;
      await pc.setRemoteDescription(new RTCSessionDescription(offer));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      socket.emit('webrtc-answer', { targetId: senderId, answer });
      processQueuedCandidates(senderId);
    });

    socket.on('webrtc-answer', async (data) => {
      const { answer, senderId } = data;
      const pc = peerConnections.current[senderId];
      if (pc && pc.signalingState === "have-local-offer") {
        await pc.setRemoteDescription(new RTCSessionDescription(answer));
        processQueuedCandidates(senderId);
      }
    });

    socket.on('webrtc-ice-candidate', async (data) => {
      const { candidate, senderId } = data;
      addCandidate(senderId, candidate);
    });

    socket.on('user-left-voice', (data) => {
      const { userId } = data;
      if (peerConnections.current[userId]) {
        peerConnections.current[userId].close();
        delete peerConnections.current[userId];
      }
      setVoiceParticipants(prev => prev.filter(p => p._id !== userId));
      setRemoteStreams(prev => { const n = { ...prev }; delete n[userId]; return n; });
    });

    // Listen for voice preview (who's in voice for any group, without joining)
    socket.on('voice-channel-preview', (data) => {
      const { groupId, users } = data;
      setVoicePreview(prev => ({ ...prev, [groupId]: users }));
    });

    return () => {
      socket.off('user-joined-voice');
      socket.off('voice-channel-users');
      socket.off('voice-channel-preview');
      socket.off('webrtc-offer');
      socket.off('webrtc-answer');
      socket.off('webrtc-ice-candidate');
      socket.off('user-left-voice');
    };
  }, [socket, localStream, isInVoice]);

  // --- SEPARATE useEffect for Private Call Handlers ---
  // These need to be always active regardless of voice channel state
  useEffect(() => {
    if (!socket) return;

    socket.on('private-call-request', (data) => {
      const { fromUserId, fromUsername, offer, isVideo } = data;
      
      // Guard: Don't process if we are the caller (we initiated this call)
      // This prevents the caller from hearing the ringtone
      // Use ref to get current value and avoid stale closure
      if (privateCallRef.current.status === 'calling' || privateCallRef.current.status === 'in-call') {
        console.log('Ignoring private-call-request - we are already in a call');
        return;
      }
      
      console.log('üìû Incoming call from:', fromUsername);
      setPrivateCall({
        status: 'receiving',
        targetUser: { _id: fromUserId, username: fromUsername },
        isVideo,
        incomingOffer: offer
      });
    });

    socket.on('private-call-accepted', async (data) => {
      const { fromUserId, answer } = data;
      const pc = peerConnections.current[fromUserId];
      if (pc && pc.signalingState === "have-local-offer") {
        await pc.setRemoteDescription(new RTCSessionDescription(answer));
        setPrivateCall(prev => ({ ...prev, status: 'in-call' }));
        processQueuedCandidates(fromUserId);
      }
    });

    socket.on('private-call-declined', () => {
      alert('Call declined');
      cleanupPrivateCall();
    });

    socket.on('private-call-ended', () => {
      cleanupPrivateCall();
    });

    socket.on('private-call-ice-candidate', async (data) => {
      const { fromUserId, candidate } = data;
      addCandidate(fromUserId, candidate);
    });

    return () => {
      socket.off('private-call-request');
      socket.off('private-call-accepted');
      socket.off('private-call-declined');
      socket.off('private-call-ended');
      socket.off('private-call-ice-candidate');
    };
  }, [socket]); // ONLY depends on socket, not localStream or isInVoice

  const initiatePrivateCall = async (targetUser, isVideo = false) => {
    const stream = await startLocalStream(isVideo); 
    if (!stream) return;
    
    setPrivateCall({ status: 'calling', targetUser, isVideo });
    setIsCameraOn(isVideo);
    localStreamRef.current = stream;
    
    const pc = createPeerConnection(targetUser._id, stream, true);
    peerConnections.current[targetUser._id] = pc;
    
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    
    socket.emit('private-call-start', {
      targetUserId: targetUser._id,
      offer,
      isVideo
    });
  };

  const acceptPrivateCall = async () => {
    const currentCall = privateCallRef.current;
    if (!currentCall.incomingOffer || !currentCall.targetUser) return;
    
    const stream = await startLocalStream(currentCall.isVideo);
    if (!stream) return;

    setIsCameraOn(currentCall.isVideo);
    localStreamRef.current = stream;
    
    const pc = createPeerConnection(currentCall.targetUser._id, stream, true);
    peerConnections.current[currentCall.targetUser._id] = pc;
    
    await pc.setRemoteDescription(new RTCSessionDescription(currentCall.incomingOffer));
    const answer = await pc.createAnswer();
    await pc.setLocalDescription(answer);
    
    socket.emit('private-call-accept', {
      targetUserId: currentCall.targetUser._id,
      answer
    });
    
    setPrivateCall(prev => ({ ...prev, status: 'in-call', incomingOffer: null }));
    processQueuedCandidates(currentCall.targetUser._id);
  };

  const declinePrivateCall = () => {
    const currentCall = privateCallRef.current;
    if (currentCall.targetUser) {
      socket.emit('private-call-decline', { targetUserId: currentCall.targetUser._id });
    }
    cleanupPrivateCall();
  };

  const endPrivateCall = () => {
    const currentCall = privateCallRef.current;
    if (currentCall.targetUser) {
      socket.emit('private-call-end', { targetUserId: currentCall.targetUser._id });
    }
    cleanupPrivateCall();
  };

  const cleanupPrivateCall = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      setLocalStream(null);
      localStreamRef.current = null;
    }
    Object.values(peerConnections.current).forEach(pc => pc.close());
    peerConnections.current = {};
    candidateQueues.current = {};
    setRemoteStreams({});
    setRemoteCameraStreams({});
    setRemoteScreenStreams({});
    setIsCameraOn(false);
    setPrivateCall({ status: 'idle', targetUser: null, isVideo: false, incomingOffer: null });
  };

  // 6. Whisper Mode Logic
  const startWhisper = (targetUserId) => {
    if (!isInVoice) return;
    setIsWhispering(true);
    setWhisperTarget(targetUserId);
    
    // In a real implementation, we would either:
    // a) Lower the volume of other remote streams local-only
    // b) Or use a separate WebRTC data channel/stream
    // For now, let's signal the intent
    socket.emit('whisper-start', { targetUserId, groupId: currentGroupId });
  };

  const stopWhisper = () => {
    setIsWhispering(false);
    setWhisperTarget(null);
  };

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      // Use clean-up logic here if needed
    };
  }, []);

  const toggleMute = () => {
    if (localStream) {
      const audioTrack = localStream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setIsMuted(!audioTrack.enabled);
      }
    }
  };

  const toggleDeafen = () => {
    const newState = !isDeafened;
    setIsDeafened(newState);
    // If we deafen, we should also mute
    if (newState && !isMuted) {
      toggleMute();
    } else if (!newState && isMuted) {
      toggleMute();
    }
  };

  return (
    <VoiceContext.Provider value={{
      isInVoice,
      voiceParticipants,
      currentGroupId,
      isMuted,
      localStream,
      remoteStreams,
      remoteCameraStreams,
      remoteScreenStreams,
      joinVoice,
      leaveVoice,
      toggleMute,
      isDeafened,
      toggleDeafen,
      isCameraOn,
      toggleCamera,
      startWhisper,
      stopWhisper,
      isWhispering,
      whisperTarget,
      isSharingScreen,
      startScreenShare,
      stopScreenShare,
      localScreenStream,
      privateCall,
      initiatePrivateCall,
      acceptPrivateCall,
      declinePrivateCall,
      endPrivateCall,
      voicePreview // Who's in voice per group (without joining)
    }}>
      {children}
      {/* Recording Logic */}
      {isInVoice && (
        <div style={{ position: 'fixed', bottom: '20px', left: '20px', zIndex: 1000 }}>
          {!isRecording ? (
            <button 
              onClick={() => startRecording()} 
              style={{ padding: '10px', borderRadius: '50%', backgroundColor: '#556158ff', color: '#fff', border: 'none', cursor: 'pointer' }}
              title="Start AI Highlight Recording"
            >
              ‚è∫Ô∏è
            </button>
          ) : (
            <button 
              onClick={() => stopRecording()} 
              style={{ padding: '10px', borderRadius: '50%', backgroundColor: '#dc3545', color: '#fff', border: 'none', cursor: 'pointer' }}
              title="Stop and Analyze Highlights"
            >
              ‚èπÔ∏è
            </button>
          )}
        </div>
      )}
    </VoiceContext.Provider>
  );
};
